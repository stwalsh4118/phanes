# 8-9 E2E CoS Test

[Back to task list](./tasks.md)

## Description

Create end-to-end tests that verify all CLI functionality meets the acceptance criteria from the PBI. This ensures the CLI works correctly as a complete system.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-01-27 00:00:00 | Created | N/A | Proposed | Task file created | sean |

## Requirements

1. Test all acceptance criteria from PBI 8:
   - CLI accepts profile, modules, config, and dry-run flags
   - CLI can list available modules and profiles
   - Profile execution works correctly
   - Module selection works correctly
   - Dry-run mode shows actions without executing
   - Config file loading and validation works
   - Help text is clear and comprehensive
   - Error handling provides actionable messages
2. Create integration tests that exercise the full CLI
3. Test both success and error paths
4. Verify output format and content

## Implementation Plan

1. Create test file: `test/integration/cli_test.go` or similar
2. Test cases:
   - **Flag parsing**: Test all Cobra flags parse correctly
   - **Help text**: Test help displays correctly
   - **List functionality**: Test `--list` shows profiles and modules
   - **Config loading**: Test config loads from file
   - **Profile execution**: Test profile selection and execution
   - **Module selection**: Test module selection and execution
   - **Dry-run mode**: Test dry-run shows actions without executing
   - **Error handling**: Test various error scenarios
3. For each test:
   - Build the binary
   - Run with appropriate flags
   - Capture output
   - Verify expected behavior
4. Mock or use test fixtures where needed:
   - Test config files
   - Test module implementations (or use real ones if available)
5. Document test scenarios and expected results

## Verification

1. All acceptance criteria are tested
2. Tests pass consistently
3. Both success and error paths are covered
4. Output is verified for correctness
5. Tests are maintainable and clear

## Test Plan

### Test Scenarios

1. **Help text**:
   - Run `./phanes --help`
   - Verify Cobra help text displays with all flags
   - Verify usage examples shown

2. **List functionality**:
   - Run `./phanes --list`
   - Verify profiles are listed
   - Verify modules are listed with descriptions

3. **Config loading**:
   - Create test config.yaml
   - Run `./phanes --config test-config.yaml --modules baseline`
   - Verify config loads successfully

4. **Profile execution**:
   - Run `./phanes --profile minimal --config test-config.yaml`
   - Verify profile modules are executed
   - Verify execution succeeds

5. **Module selection**:
   - Run `./phanes --modules baseline,user --config test-config.yaml`
   - Verify selected modules execute
   - Verify execution order

6. **Dry-run mode**:
   - Run `./phanes --dry-run --modules baseline --config test-config.yaml`
   - Verify dry-run mode is enabled in logs
   - Verify modules check but don't install

7. **Error handling**:
   - Test invalid profile: `./phanes --profile invalid`
   - Test invalid config: `./phanes --config nonexistent.yaml`
   - Test invalid module: `./phanes --modules invalid`
   - Verify error messages are clear and actionable

8. **Flag validation**:
   - Test missing required flags (if any)
   - Test conflicting Cobra flags (if any)
   - Verify validation errors

## Files Modified

- `test/integration/cli_test.go` (new) or appropriate test location

